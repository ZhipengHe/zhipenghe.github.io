---
---



@article{Honours2021,
	selected = false,
	author = {Zhipeng He}, 
	title = {Investigating the Impact of Event Logs on Deep Learning-based Process Prediction Performance},
	journal = {Queensland University of Technology},
	year = {2021},
	abbr = {Honours},
	abstract = {Business process predictive analytics exploit historical process execution logs, known as event logs, to generate predictions of running cases of a business process, such as next event or remaining time. In the state-of-the-art approaches, deep learning algorithms have attracted increasing attention and as a result deep learning-based prediction models become the mainstream of the research. Often encoding methods for event logs and neural network architectures have been considered as two factors that would impact models' prediction performance. In fact, an event log, as the input data for prediction, also plays an important role in the predictive pipeline and should not be overlooked. However, there is no recent research concerning with the potential influence of event logs on prediction performance. This thesis aims to investigate how different event logs affect the performance of deep learning-based process prediction models. We propose and implement a benchmark on two different encoding methods and three Long Short-Term Memory (LSTM) models with seven real-life event logs for predicting next activity, next resource and next interval time. Based on the above benchmark, this thesis explores and analyses some key characteristics of event logs and extracts findings on relationships between the characteristics of event logs and performance of process prediction models.},
	note = {Honours Thesis},
	pdf = {Honours_Thesis.pdf}
}

@article{KBS2022,
	abstract = {Predictive process analytics, often underpinned by deep learning techniques, is a newly emerged discipline dedicated for providing business process intelligence in modern organisations. Whilst accuracy has been a dominant criterion in building predictive capabilities, the use of deep learning techniques comes at the cost of the resulting models being used as `black boxes', i.e., they are unable to provide insights into why a certain business process prediction was made. So far, little attention has been paid to interpretability in the design of deep learning-based process predictive models. In this paper, we address the `black-box' problem in the context of predictive process analytics by developing attention-based models that are capable to inform both what and why is a process prediction. We propose i) two types of attentions---event attention to capture the impact of specific events on a prediction, and attribute attention to reveal which attribute(s) of an event influenced the prediction; and ii) two attention mechanisms---shared attention mechanism and specialised attention mechanism to reflect different design decisions between whether to construct attribute attention on individual input features (specialised) or using the concatenated feature tensor of all input feature vectors (shared). These lead to two distinct attention-based models, and both are interpretable models that incorporate interpretability directly into the structure of a process predictive model. We conduct experimental evaluation of the proposed models using real-life dataset and comparative analysis between the models for accuracy and interpretability, and draw insights from the evaluation and analysis results. The results demonstrate that i) the proposed attention-based models can achieve reasonably high accuracy; ii) both are capable of providing relevant interpretations (when validated against domain knowledge); and iii) whilst the two models perform equally in terms of prediction accuracy, the specialised attention-based model tends to provide more relevant interpretations than the shared attention-based model, reflecting the fact that the specialised attention-based model is designed to facilitate better interpretability.},
	author = {Bemali Wickramanayake and Zhipeng He and Chun Ouyang and Catarina Moreira and Yue Xu and Renuka Sindhgatta},
	doi = {10.1016/j.knosys.2022.108773},
	journal = {Knowledge-Based Systems},
	keywords = {Explainable AI, Attention mechanism, Business process prediction, Event log, LSTM},
	pages = {108773},
	title = {Building interpretable models for business process prediction using shared and specialised attention mechanisms},
	year = {2022},
	selected=true,
	abbr={KBS},
	html = {https://doi.org/10.1016/j.knosys.2022.108773}
}

@article{Physionet2022,
	abstract = {In this work, we extract an event log from the MIMIC-IV-ED dataset by adopting a well-established event log generation methodology, and we name this event log MIMICEL. The data tables in the MIMIC-IV-ED dataset relate to each other based on the existing relational database schema, and each table records the individual activities of patients along their journey in the emergency department (ED). While the data tables in the MIMIC-IV-ED dataset catch snapshots of a patient journey in the ED, the extracted event log MIMICEL aims to capture an end-to-end patient journey process. This will enable us to analyse the existing patient flows, thereby improving the efficiency of an ED process.},
	author = {Jia Wei and Zhipeng He and Chun Ouyang and Catarina Moreira},
	title = {MIMICEL: MIMIC-IV Event Log for Emergency Department},
	journal = {Physionet},
	year = {2022},
	doi = {10.13026/64aq-jw11},
	html = {https://doi.org/10.13026/64aq-jw11},
	selected = false,
	abbr={MIMIC},
	note = {Version 1.0.0}
}

@article{ISWA2024,
	abstract = {Adversarial attacks are a potential threat to machine learning models by causing incorrect predictions through imperceptible perturbations to the input data. While these attacks have been extensively studied in unstructured data like images, applying them to tabular data, poses new challenges. These challenges arise from the inherent heterogeneity and complex feature interdependencies in tabular data, which differ from the image data. To account for this distinction, it is necessary to establish tailored imperceptibility criteria specific to tabular data. However, there is currently a lack of standardised metrics for assessing the imperceptibility of adversarial attacks on tabular data. To address this gap, we propose a set of key properties and corresponding metrics designed to comprehensively characterise imperceptible adversarial attacks on tabular data. These are: proximity to the original input, sparsity of altered features, deviation from the original data distribution, sensitivity in perturbing features with narrow distribution, immutability of certain features that should remain unchanged, feasibility of specific feature values that should not go beyond valid practical ranges, and feature interdependencies capturing complex relationships between data attributes. We evaluate the imperceptibility of five adversarial attacks, including both bounded attacks and unbounded attacks, on tabular data using the proposed imperceptibility metrics. The results reveal a trade-off between the imperceptibility and effectiveness of these attacks. The study also identifies limitations in current attack algorithms, offering insights that can guide future research in the area. The findings gained from this empirical analysis provide valuable direction for enhancing the design of adversarial attack algorithms, thereby advancing adversarial machine learning on tabular data.},
	author = {Zhipeng He and Chun Ouyang and Laith Alzubaidi and Alistair Barros and Catarina Moreira},
	title = {Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis},
	keywords = {Adversarial examples, Imperceptibility, Machine learning models, Robustness, Tabular data},
	doi = {10.48550/arXiv.2407.11463},
	html = {https://arxiv.org/abs/2407.11463},
	journal = {Intelligent Systems with Applications},
	year = {2024},
	selected = true,
	abbr={ISWA},
	note = {Accepted, to appear},
	poster = {https://slides.zhipenghe.me/2024-12-ADSN.pdf}
}